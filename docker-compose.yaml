version: '3'
services:
  # Minio
  #  minio:
  #    container_name: uc-minio
  #    image: quay.io/minio/minio
  #    ports:
  #      - "9000:9000"
  #      - "9001:9001"
  #    volumes:
  #      - ./app/data/minio:/data
  #    command: [ "server", "/data", "--console-address", ":9001" ]

  # Unity Catalog
  uc-server:
    container_name: uc-server
    build:
      context: submodules/unitycatalog
      dockerfile: Dockerfile
    ports:
      - "8088:8080"
    environment:
      - AWS_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    volumes:
      - ./dockers/uc/etc/conf/server.properties:/home/unitycatalog/etc/conf/server.properties

  uc-ui:
    container_name: uc-ui
    build:
      context: submodules/unitycatalog/ui
      dockerfile: Dockerfile
      args:
        PROXY_HOST: uc-server
    ports:
      - "3000:3000"
    environment:
      - AWS_ENDPOINT_URL=http://minio:9000
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    depends_on:
      - uc-server
  # Spark
  spark-master:
    container_name: uc-spark-master
    build:
      context: dockers/spark
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - UC_SERVER=http://uc-server:8080
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    volumes:
      - ./log/spark-events:/opt/spark/spark-events
      - ./app:/app
    command: bash -c "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"

  spark-worker:
    container_name: uc-spark-worker
    build:
      context: dockers/spark
      dockerfile: Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://uc-spark-master:7077
      - UC_SERVER=http://uc-server:8080
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    volumes:
      - ./log/spark-events:/opt/spark/spark-events
      - ./app:/app
    command: bash -c "/opt/spark/sbin/start-worker.sh spark://uc-spark-master:7077 && tail -f /opt/spark/logs/*"
    depends_on:
      - spark-master

  spark-history:
    container_name: uc-spark-history
    build:
      context: dockers/spark
      dockerfile: Dockerfile
    ports:
      - "18080:18080"
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=/opt/spark/spark-events"
      - SPARK_CLEANER_ENABLED=false
      - UC_SERVER=http://uc-server:8080
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
    volumes:
      - ./log/spark-events:/opt/spark/spark-events
    command: bash -c "/opt/spark/sbin/start-history-server.sh  && tail -f /opt/spark/logs/*"
    depends_on:
      - spark-master

  # Trino
  trino-server:
    container_name: uc-trino-server
    image: trinodb/trino:latest
    ports:
      - "8089:8080"
    volumes:
      - ./dockers/trino/etc/catalog:/etc/trino/catalog
      - ./dockers/trino/etc/log.properties:/etc/trino/log.properties
    depends_on:
      - uc-server
  # StarRocks
  starrocks-server:
    container_name: uc-starrocks-server
    image: starrocks/allin1-ubuntu
    ports:
      - "9030:9030"
      - "8030:8030"
      - "8040:8040"
    volumes:
      - ./dockers/starrocks/setup_catalog.sh:/data/deploy/setup_catalog.sh
    #    command: >
    #      sh -c "
    #      /data/deploy/entrypoint.sh &&
    #      sh /data/deploy/setup_catalog.sh"
    depends_on:
      - uc-server
